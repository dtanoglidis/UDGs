{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "# Import stuff\n",
    "import numpy as np\n",
    "import scipy\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from astropy.io import fits\n",
    "from code.plot_utils import plot_pretty\n",
    "from astropy import units as u\n",
    "from astropy.coordinates import SkyCoord\n",
    "from matplotlib import rcParams\n",
    "rcParams['font.family'] = 'serif'\n",
    "\n",
    "%matplotlib inline\n",
    "%pylab inline \n",
    "plot_pretty() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "coadd_id = []\n",
    "ra = []\n",
    "dec = []\n",
    "A_IMAGE = []\n",
    "B_IMAGE = []\n",
    "MAG_AUTO_G = []\n",
    "FLUX_RADIUS_G = []\n",
    "MU_EFF_MODEL_G = []\n",
    "MU_MAX_G = []\n",
    "MU_MAX_MODEL_G = []\n",
    "MU_MEAN_MODEL_G = []\n",
    "MAG_AUTO_R = []\n",
    "FLUX_RADIUS_R = []\n",
    "MU_EFF_MODEL_R = []\n",
    "MU_MAX_R = []\n",
    "MU_MAX_MODEL_R = []\n",
    "MU_MEAN_MODEL_R = []\n",
    "MAG_AUTO_I = []\n",
    "FLUX_RADIUS_I = []\n",
    "MU_EFF_MODEL_I = []\n",
    "MU_MAX_I = []\n",
    "MU_MAX_MODEL_I = []\n",
    "MU_MEAN_MODEL_I = []\n",
    "SPREADERR_MODEL_I = []\n",
    "SPREAD_MODEL_I = []\n",
    "FLAGS_GOLD = []\n",
    "EXTENDED_CLASS_COADD = []\n",
    "EXTENDED_CLASS_MOF = []\n",
    "BPZ_ZMEAN_MOF = []\n",
    "BPZ_ZMC_MOF = []\n",
    "DNF_ZMC_MOF = []\n",
    "DNF_ZMEAN_MOF = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i in range(1,1754):\n",
    "    DES_dat = fits.open('DES_Y3_{0}.fits'.format(i))\n",
    "    \n",
    "    coadd_id_n = DES_dat[1].data['COADD_OBJECT_ID']\n",
    "    ra_n = DES_dat[1].data['RA']\n",
    "    dec_n = DES_dat[1].data['DEC']\n",
    "    A_IMAGE_n = DES_dat[1].data['A_IMAGE']\n",
    "    B_IMAGE_n = DES_dat[1].data['B_IMAGE']\n",
    "    MAG_AUTO_G_n = DES_dat[1].data['MAG_AUTO_G']\n",
    "    FLUX_RADIUS_G_n = 0.263*DES_dat[1].data['FLUX_RADIUS_G']\n",
    "    MU_EFF_MODEL_G_n = DES_dat[1].data['MU_EFF_MODEL_G']\n",
    "    MU_MAX_G_n = DES_dat[1].data['MU_MAX_G']\n",
    "    MU_MAX_MODEL_G_n = DES_dat[1].data['MU_MAX_MODEL_G']\n",
    "    MU_MEAN_MODEL_G_n = DES_dat[1].data['MU_MEAN_MODEL_G']\n",
    "    MAG_AUTO_R_n = DES_dat[1].data['MAG_AUTO_R']\n",
    "    FLUX_RADIUS_R_n = 0.263*DES_dat[1].data['FLUX_RADIUS_R']\n",
    "    MU_EFF_MODEL_R_n = DES_dat[1].data['MU_EFF_MODEL_R']\n",
    "    MU_MAX_R_n = DES_dat[1].data['MU_MAX_R']\n",
    "    MU_MAX_MODEL_R_n = DES_dat[1].data['MU_MAX_MODEL_R']\n",
    "    MU_MEAN_MODEL_R_n = DES_dat[1].data['MU_MEAN_MODEL_R']\n",
    "    MAG_AUTO_I_n = DES_dat[1].data['MAG_AUTO_I']\n",
    "    FLUX_RADIUS_I_n = 0.263*DES_dat[1].data['FLUX_RADIUS_I']\n",
    "    MU_EFF_MODEL_I_n = DES_dat[1].data['MU_EFF_MODEL_I']\n",
    "    MU_MAX_I_n = DES_dat[1].data['MU_MAX_I']\n",
    "    MU_MAX_MODEL_I_n = DES_dat[1].data['MU_MAX_MODEL_I']\n",
    "    MU_MEAN_MODEL_I_n = DES_dat[1].data['MU_MEAN_MODEL_I']\n",
    "    SPREADERR_MODEL_I_n = DES_dat[1].data['SPREADERR_MODEL_I']\n",
    "    SPREAD_MODEL_I_n = DES_dat[1].data['SPREAD_MODEL_I']\n",
    "    FLAGS_GOLD_n = DES_dat[1].data['FLAGS_GOLD']\n",
    "    EXTENDED_CLASS_COADD_n = DES_dat[1].data['EXTENDED_CLASS_COADD']\n",
    "    EXTENDED_CLASS_MOF_n = DES_dat[1].data['EXTENDED_CLASS_MOF']\n",
    "    BPZ_ZMEAN_MOF_n = DES_dat[1].data['BPZ_ZMEAN_MOF']\n",
    "    BPZ_ZMC_MOF_n = DES_dat[1].data['BPZ_ZMC_MOF']\n",
    "    DNF_ZMC_MOF_n = DES_dat[1].data['DNF_ZMC_MOF']\n",
    "    DNF_ZMEAN_MOF_n = DES_dat[1].data['DNF_ZMEAN_MOF']\n",
    "    \n",
    "    # now concatenate\n",
    "    \n",
    "    coadd_id = np.concatenate((coadd_id ,coadd_id_n))\n",
    "    ra = np.concatenate((ra, ra_n))\n",
    "    dec = np.concatenate((dec, dec_n))\n",
    "    A_IMAGE = np.concatenate((A_IMAGE, A_IMAGE_n))\n",
    "    B_IMAGE = np.concatenate((B_IMAGE, B_IMAGE_n))\n",
    "    MAG_AUTO_G = np.concatenate((MAG_AUTO_G, MAG_AUTO_G_n))\n",
    "    FLUX_RADIUS_G = np.concatenate((FLUX_RADIUS_G, FLUX_RADIUS_G_n))\n",
    "    MU_EFF_MODEL_G = np.concatenate((MU_EFF_MODEL_G, MU_EFF_MODEL_G_n))\n",
    "    MU_MAX_G = np.concatenate((MU_MAX_G, MU_MAX_G_n))\n",
    "    MU_MAX_MODEL_G = np.concatenate((MU_MAX_MODEL_G, MU_MAX_MODEL_G_n))\n",
    "    MU_MEAN_MODEL_G = np.concatenate((MU_MEAN_MODEL_G, MU_MEAN_MODEL_G_n))\n",
    "    MAG_AUTO_R = np.concatenate((MAG_AUTO_R, MAG_AUTO_R_n))\n",
    "    FLUX_RADIUS_R = np.concatenate((FLUX_RADIUS_R, FLUX_RADIUS_R_n))\n",
    "    MU_EFF_MODEL_R = np.concatenate((MU_EFF_MODEL_R, MU_EFF_MODEL_R_n))\n",
    "    MU_MAX_R = np.concatenate((MU_MAX_R, MU_MAX_R_n))\n",
    "    MU_MAX_MODEL_R = np.concatenate((MU_MAX_MODEL_R, MU_MAX_MODEL_R_n))\n",
    "    MU_MEAN_MODEL_R = np.concatenate((MU_MEAN_MODEL_R, MU_MEAN_MODEL_R_n))\n",
    "    MAG_AUTO_I = np.concatenate((MAG_AUTO_I, MAG_AUTO_I_n))\n",
    "    FLUX_RADIUS_I = np.concatenate((FLUX_RADIUS_I, FLUX_RADIUS_I_n))\n",
    "    MU_EFF_MODEL_I = np.concatenate((MU_EFF_MODEL_I, MU_EFF_MODEL_I_n))\n",
    "    MU_MAX_I = np.concatenate((MU_MAX_I, MU_MAX_I_n))\n",
    "    MU_MAX_MODEL_I = np.concatenate((MU_MAX_MODEL_I, MU_MAX_MODEL_I_n))\n",
    "    MU_MEAN_MODEL_I = np.concatenate((MU_MEAN_MODEL_I, MU_MEAN_MODEL_I_n))\n",
    "    SPREADERR_MODEL_I = np.concatenate((SPREADERR_MODEL_I, SPREADERR_MODEL_I_n))\n",
    "    SPREAD_MODEL_I = np.concatenate((SPREAD_MODEL_I, SPREAD_MODEL_I_n))\n",
    "    FLAGS_GOLD = np.concatenate((FLAGS_GOLD, FLAGS_GOLD_n))\n",
    "    EXTENDED_CLASS_COADD = np.concatenate((EXTENDED_CLASS_COADD, EXTENDED_CLASS_COADD_n))\n",
    "    EXTENDED_CLASS_MOF = np.concatenate((EXTENDED_CLASS_MOF, EXTENDED_CLASS_MOF_n))\n",
    "    BPZ_ZMEAN_MOF = np.concatenate((BPZ_ZMEAN_MOF , BPZ_ZMEAN_MOF_n))\n",
    "    BPZ_ZMC_MOF = np.concatenate((BPZ_ZMC_MOF, BPZ_ZMC_MOF_n))\n",
    "    DNF_ZMC_MOF = np.concatenate((DNF_ZMC_MOF, DNF_ZMC_MOF_n))\n",
    "    DNF_ZMEAN_MOF = np.concatenate((DNF_ZMEAN_MOF, DNF_ZMEAN_MOF_n))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "413608\n"
     ]
    }
   ],
   "source": [
    "print(len(ra))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "from sklearn.externals import joblib \n",
    "from sklearn import preprocessing\n",
    "scaler = joblib.load('Scaler.pkl')\n",
    "# Load the model from the file \n",
    "SVM_class = joblib.load('Classifier.pkl') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Define the ellipticity now\n",
    "ellipticity = 1.0 - B_IMAGE/A_IMAGE\n",
    "\n",
    "# ===========================================================================================\n",
    "# Define the colors\n",
    "col_g_r = MAG_AUTO_G - MAG_AUTO_R\n",
    "col_g_i = MAG_AUTO_G - MAG_AUTO_I\n",
    "col_i_r = MAG_AUTO_G - MAG_AUTO_R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define the train data matrix of features\n",
    "X_feat = np.zeros([len(ra),18])\n",
    "X_feat[:,0] = MAG_AUTO_G;X_feat[:,1] = MAG_AUTO_R;X_feat[:,2] = MAG_AUTO_I\n",
    "X_feat[:,3] = col_g_r;X_feat[:,4] = col_g_i;X_feat[:,5] = col_i_r\n",
    "X_feat[:,6] = FLUX_RADIUS_G;X_feat[:,7] = FLUX_RADIUS_R;X_feat[:,8] = FLUX_RADIUS_I\n",
    "X_feat[:,9] = MU_EFF_MODEL_G;X_feat[:,10] = MU_EFF_MODEL_R;X_feat[:,11] = MU_EFF_MODEL_I\n",
    "X_feat[:,12] = MU_MAX_G; X_feat[:,13] =  MU_MAX_R;X_feat[:,14] =  MU_MAX_I\n",
    "X_feat[:,15] = ellipticity;X_feat[:,16] = A_IMAGE; X_feat[:,17] = B_IMAGE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Preprocess and classify\n",
    "X_feat = scaler.transform(X_feat)\n",
    "y_pred = SVM_class.predict(X_feat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Keep those positively classified\n",
    "RA_pos = ra[y_pred==1.]\n",
    "DEC_pos = dec[y_pred==1.]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40820\n"
     ]
    }
   ],
   "source": [
    "print(len(RA_pos))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Now, I want to split this into smaller files of 500 candidates each, in order to be able to easily distribute them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 0, 499)\n",
      "(1, 500, 999)\n",
      "(2, 1000, 1499)\n",
      "(3, 1500, 1999)\n",
      "(4, 2000, 2499)\n",
      "(5, 2500, 2999)\n",
      "(6, 3000, 3499)\n",
      "(7, 3500, 3999)\n",
      "(8, 4000, 4499)\n",
      "(9, 4500, 4999)\n",
      "(10, 5000, 5499)\n",
      "(11, 5500, 5999)\n",
      "(12, 6000, 6499)\n",
      "(13, 6500, 6999)\n",
      "(14, 7000, 7499)\n",
      "(15, 7500, 7999)\n",
      "(16, 8000, 8499)\n",
      "(17, 8500, 8999)\n",
      "(18, 9000, 9499)\n",
      "(19, 9500, 9999)\n",
      "(20, 10000, 10499)\n",
      "(21, 10500, 10999)\n",
      "(22, 11000, 11499)\n",
      "(23, 11500, 11999)\n",
      "(24, 12000, 12499)\n",
      "(25, 12500, 12999)\n",
      "(26, 13000, 13499)\n",
      "(27, 13500, 13999)\n",
      "(28, 14000, 14499)\n",
      "(29, 14500, 14999)\n",
      "(30, 15000, 15499)\n",
      "(31, 15500, 15999)\n",
      "(32, 16000, 16499)\n",
      "(33, 16500, 16999)\n",
      "(34, 17000, 17499)\n",
      "(35, 17500, 17999)\n",
      "(36, 18000, 18499)\n",
      "(37, 18500, 18999)\n",
      "(38, 19000, 19499)\n",
      "(39, 19500, 19999)\n",
      "(40, 20000, 20499)\n",
      "(41, 20500, 20999)\n",
      "(42, 21000, 21499)\n",
      "(43, 21500, 21999)\n",
      "(44, 22000, 22499)\n",
      "(45, 22500, 22999)\n",
      "(46, 23000, 23499)\n",
      "(47, 23500, 23999)\n",
      "(48, 24000, 24499)\n",
      "(49, 24500, 24999)\n",
      "(50, 25000, 25499)\n",
      "(51, 25500, 25999)\n",
      "(52, 26000, 26499)\n",
      "(53, 26500, 26999)\n",
      "(54, 27000, 27499)\n",
      "(55, 27500, 27999)\n",
      "(56, 28000, 28499)\n",
      "(57, 28500, 28999)\n",
      "(58, 29000, 29499)\n",
      "(59, 29500, 29999)\n",
      "(60, 30000, 30499)\n",
      "(61, 30500, 30999)\n",
      "(62, 31000, 31499)\n",
      "(63, 31500, 31999)\n",
      "(64, 32000, 32499)\n",
      "(65, 32500, 32999)\n",
      "(66, 33000, 33499)\n",
      "(67, 33500, 33999)\n",
      "(68, 34000, 34499)\n",
      "(69, 34500, 34999)\n",
      "(70, 35000, 35499)\n",
      "(71, 35500, 35999)\n",
      "(72, 36000, 36499)\n",
      "(73, 36500, 36999)\n",
      "(74, 37000, 37499)\n",
      "(75, 37500, 37999)\n",
      "(76, 38000, 38499)\n",
      "(77, 38500, 38999)\n",
      "(78, 39000, 39499)\n",
      "(79, 39500, 39999)\n",
      "(80, 40000, 40499)\n"
     ]
    }
   ],
   "source": [
    "for i in range(81):\n",
    "    print(i, 500*i, 500*i+499)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i in range(81):\n",
    "    \n",
    "    start = 500*i\n",
    "    end = 500*i+500\n",
    "    ra_loc = RA_pos[start:end]\n",
    "    dec_loc = DEC_pos[start:end]\n",
    "    \n",
    "    j = 1+i\n",
    "    np.savetxt('Candidates_file_{0}.dat'.format(j), np.c_[ra_loc, dec_loc], fmt='%.6f %.6f ')\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.savetxt('Candidates_file_82.dat', np.c_[RA_pos[40500:], DEC_pos[40500:]], fmt='%.6f %.6f ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
